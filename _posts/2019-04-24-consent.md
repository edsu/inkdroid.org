---
title: Consent Content
layout: post
tags:
- ethics
- social media
---

In the [second phase] of the [Documenting the Now] project we are continuing to support and develop [tools] that embody ethical practices for social media archiving. This work is being informed by a series of [workshops] with activist communities, as well an effort to bring social media archiving practices [into the college classroom]. The structure of the project reflects an understanding that was developed early on in Phase 1 of the project, that one of the biggest challenges that social media archiving practice faces is how to meaningfully work with issues of *consent*.

Simply because a user has quickly agreed to a social media platform's *Terms of Service* does not mean that they have agreed to have their content collected and preserved for the long term in an archive. Consider the case of the not fully realized Library of Congress Twitter archive, in which users had no opportunity to opt-in or opt-out of having their tweets archived for perpetuity. This archive, and an increased anxiety about the archival nature of social media, gave rise to a variety of services like [Tweet Delete], [Tweet Wipe] and [Tweet Deleter] that allow you to routinely or fully purge your Twitter history. I think it's productive to look at these services as a mirror of [records management] processes in more traditional archives, where appraisal and retention schedules determine what records are placed into an archive, how long particular records are to be held.

I also think it's interesting to speculate for a moment how the Library of Congress Twitter partnership could have been significantly altered if Twitter had added a checkbox to the user settings page to indicate whether to archive a user's posts and media at the Library of Congress. What should the default setting have been? How could it have been explained? You may think that this is no longer an issue for the Library of Congress since they have stopped archiving all public tweets [@LC:2017]:

> As the twelfth year of Twitter draws to a close, the Library has 
> decided to change its collection strategy for receipt of tweets on 
> December 31, 2017. After this time, the Library will continue to 
> acquire tweets but will do so on a very selective basis under the 
> overall guidance provided in the Libraryâ€™s Collections Policy 
> Statements and associated documents. Generally, the tweets collected 
> and archived will be thematic and event-based, including events 
> such as elections, or themes of ongoing national interest, e.g. 
> public policy.

But even when *selectively* archiving content from social media, doesn't consent still play a significant role? If the content is created by public figures, such as elected officials, a strong case can be made that consent isn't so much of an issue. After all, these are individuals that are familiar with being in the limelight, and often have teams of people that help them manage it. But this is definitely not be the case for all people posting with an election hashtag. Furthermore, if only public figures' tweets are to be made part of the historical record, doesn't that privilege particular voices in society? Doesn't that privileging shortchange the democratic and transformational potential of having a social media archive in the first place?

These issues of consent were brought into stark relief for us, on a much smaller scale, as we collected [28,560,078 tweets] surrounding the protests in Ferguson after the murder of Michael Brown, and the subsequent decision not to indict Darren Wilson who is the police officer that killed him. We were [interested] in how these tweets from people on the ground mobilized media awareness of the events in Ferguson, and documented the subsequent state response. We were interested in how these individual and collective voices formed an essential part of the historical record, and as documentation for achieving social justice. Our work was operating out of a concern that if archivists aren't able to collect this material when needed, then these voices and their actions would be lost to history, and forgotten.

However, as we learned, we were not the only actors who were interested in collecting this material. Law enforcement, and the [technology] [companies] that serve them, were actively collecting and analyzing Ferguson tweets too. Some of them contacted us directly asking for access to the tweets we had collected. These corporate and government actors were also interested in the voices of the Ferguson community, and the many people that traveled there to participate in the protests, but for purposes of political and social control--not social justice and history. They wanted to be able to use this data in order to *predict* when uprisings occur, in order to foreclose on them, and to identify, track and incarcerate the people involved.

This should come as no surprise to archival practitioners and scholars who understand that archives are always instruments and sites for the exercise of power. Whether they are managed by an archivist at a large state institution, or a policy expert working at a social media company, or by a volunteer in a small community archive, or an individual scholar as they do field work onsite, record keeping practices both enact power, and hold power accountable [@Ketelaar:2002].

Archival practices can reinforce and calcify dominant cultural forms, or augment, subvert, destabilize and overcome them by offering *counterstories* that surface submerged records, and present multiple narratives and truths [@Dunbar:2006]. The key question for us then became, *whose* power is our Ferguson archive serving? As Dunbar writes, Critical Race Theory (CRT) provides a lens for examining what medial forms are permitted in an archive, and stresses the importance, and degree to which record creators can participate in the creation of archives:

> CRT techniques of evidential rectifying could be useful to archival
> discourse in terms of broadening notions of what constitutes a record,
> the role of human subjects documented as co-creators of the record,
> and assumptions about archives and archivists as neutral third parties
> in the preservation and use of the record and other forms of
> historical evidence. (p. 114)

This analysis, and archival approaches to social justice more generally [@Punzalan:2016 ; @Flinn:2011], informed our own work, but we were left with the conundrum of how to enact these principles while working with millions of records from hundreds of thousands of people. What does consent mean at that scale? Is consent, as it is conventionally framed, even the right conceptual tool to center in our own application designs? The expedient answer to these questions is to say consent can't be done at scale and either a) ignore social media archiving, or b) say the ethics of consent don't apply and collect it all. We chose instead to inform some of the design work we will be doing in Phase 2 by reviewing the archival and human computer interaction (HCI) research literature around consent and social media data collection, to see what the state of the art was. Here are a few things we've found so far.

### Terms of Service are Inadequate

The general consensus, which many of us know from direct experience, is that Terms of Service (ToS), End User License Agreements (EULA) as currently construed, are ineffective for managing users expectations of how their data will be used. We all have the experience of signing up for a new service and being presented with a long EULA or Terms of Service document, which we must agree to in order to continue. @McDonald:2008 estimate that it would take approximately 201 hours per year for an individual (reading at 250 words per minute) to read all the Terms of Service documents that an individual encounters per year. In terms of the number of people online in the United States, and the average income, this expenditure in time would amount to $781 billion dollars per year. Most of us cannot make that kind of time commitment, and so the ToS documents go unread. 

The purpose of these ToS documents is to reduce power asymmetries between corporate and government entities and individuals. Legal theories around privacy and consent assume an informed, rational and autonomous data subject. However, in a digital environment these assumptions have led to some rather pernicious side effects where individuals are inundated with increasingly opaque requests for consent. As noted by @Schermer:2014, increased regulation around consent, such as the General Data Protection Regulation (GDPR), can lead to *Consent Transaction Overload* where users are desensitized to the importance of consent. Paternalistic approaches to consent result in users blindly accepting cookie notifications, and clicking through consent transactions in order to get on with whatever they are doing.

Even if users were able to spend the time required to read ToS documents, it is unlikely that they would understand the full ramifications of their choices. @Acquisit:2005 found that 41% of individuals with high privacy concerns admit that they don't read privacy policies. Individuals generally lack sufficient information to make decisions about their privacy and often trade off their long-term privacy for short term benefits. And as Schermer indicates, it is increasingly unlikely that the we as individuals will be able to comprehend the processual flows of data bound up in the computer systems described by ToS policies:

> as data processing becomes more and more complex, more factors need to 
> be taken into account. The result is that the reality of data processing
> will become even further removed from the simplistic mental models 
> employed by data subjects.

Internet protocols allow data to be easily copied, and instantly transported at great distance, which can yield extremely complex, forking data flows, that can lead to a loss of control of information as it moves between contexts. @Nissenbaum:2011 refers to this as the *Transparency Paradox* where the full picture of these processual flows cannot be understood, let alone read, while on the other hand, summarizing practices remove details that could be quite important--the hidden 

Also, Belmont princples are themselves inadequate (Vitak)

- legal theory assumes an informed and rational data subject, too many requests for consent, absence of meaningful choices, and paternalistic approaches that require such consent may desensitize people further (Schermer 2014)
- Constantly asking for permission is also problematic people just respond immediately (Custers 2013)
- Belmont Report is antiquated: Vitak
- Efforts to provide informed consent are counter-productive because users have been trained to quickly click consent dialog boxes. (Bohme:2010)
- EULA have asymmetrical power relations embedded in them 
- Consent changes over time and terms change (Custers, 2016 ; Nissenbaum, 2011)
- GDPR benefits and critiques?
- Hawthorne effect: observer effect - does this matter for Humanities work? (Galinas)
- https://www.darkpatterns.org/

### Solutions 

- consent is transformative (ethics chapter, philosophy)
- trust (Metzger, 2006)
- better design of information (Schaub, 2015) from Acquisti:2017 p. 44:14
- gap between what individuals want and ToS documents isn't unsurmountable.  most criteria that are important to users can be found in most privacy policies [@Custers:2014].
- design ideas! Schaub:2015 ; every design choice is a nudge, Acquisti:2017 ; A/B testing treating us like lab rats
- p3p semweb Cranor:2002, now machine learning w/ archive of ToS Wilson:2016 and Wilson:2016a

- burden / validity tension
- expiration of consent (Custers, 2016)
- Contextual Integrity: between secured consent and sustained consent (Hutton, 2015). balancing 
- normative aspect to contextual integrity: what are norms, how are they measured
- Human Data Interaction: legibility, agency, negotiability (Hutton, 2017)

- Making ToS more readable. (McDonald)

### Archival Solutions

- time 
- third party privacy & contextual integrity (Bingo, 2011)
- participatory archives
- oral history ethics?

### App Design

### References

[second phase]: https://news.docnow.io/documenting-the-now-phase-2-83d76a9ee0a8
[tools]: https://github.com/docnow/
[Documenting the Now]: https://www.docnow.io
[28,560,078 tweets]: https://archive.org/details/ferguson-tweet-ids
[interested]: https://medium.com/on-archivy/documenting-the-now-ferguson-in-the-archives-adcdbe1d5788
[workshops]: https://twitter.com/documentnow/status/1110555760948199425
[into the college classroom]: https://news.virginia.edu/content/black-twitter-101-what-it-where-did-it-originate-where-it-headed
[Tweet Delete]: https://tweetdelete.net/
[Tweet Wipe]: https://twitwipe.com/
[Tweet Deleter]: https://tweetdeleter.com/
[technology]: https://www.baltimoresun.com/news/maryland/investigations/bs-md-geofeedia-police-20160902-story.html
[companies]: https://www.typeinvestigations.org/investigation/2018/02/27/palantir-secretly-use-new-orleans-test-predictive-policing
[records management]: https://en.wikipedia.org/wiki/Records_management

