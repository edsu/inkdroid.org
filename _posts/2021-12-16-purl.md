---
title: A bit about PURLs
tags:
- metadata
- identifiers
- data
layout: post
---

One of my first jobs after finishing an MLS was as a "metadata librarian" at
Old Dominion University. This was back in 1998, so it was fitting that one of
my first projects was cleaning up all these newfangled *URLs* that had started
popping up in our online catalog.

Many of these records flowed directly in because ODU, like many libraries
around the US, participated in the [Federal Depository Library Program], which
meant that we imported MARC records for the [GPO] publications that the library
selected. Many of these MARC records included [856] fields which pointed at
digital equivalents on the emerging web. Sometimes the publications were *only*
available online, which seemed to be the case for datasets that were no longer
being distributed on CD-ROM. In these times of [Bandcamp](https://bandcamp.com)
getting datasets sent on physical media by the post seems like a feature not
a bug right? Maybe some are still distributed this way?

The idea that you could click on some text in the catalog (a link) and read the
described document was a revolution in consciousness--when it worked.
Unfortunately many of these URLs had broken even in the short time that they
were in the catalog. They needed to be either updated or removed so that
library patrons didn't go down 404 dead ends when consulting the catalog.

That's when I first ran across the idea of the [Persistent Uniform Resource
Locator] or PURL. I noticed that some of the URLs were starting to all have the
same hostname *purl.fdlp.gov*. PURLs were [created] by Stuart Weibel and Erik
Jul at OCLC in 1995, and were picked up by the GPO in 1997 as a way to mitigate
broken URLs. The FDLP and GPO are still using PURLs today.

I guess PURL is the original URL shortener. But it was created not to
abbreviate otherwise long and otherwise cumbersome URLs, but to make them more
resilient and persistent over time. You could put a PURL into a catalog record
and if the URL it pointed to needed to change you changed the redirect on the
PURL server, and all the places that pointed to the PURL didn't need to change.
It was a beautifully simple idea, and has influenced other approaches like DOI
and Handle. But this simplicity depends on a commitment to keeping the PURL up
to date, because:

> ... every PID is a service commitment involving at least some sweat equity.
[@Kunze:2018]

PURLs are only as good as the maintenance work that has gone into updating the
underlying URLs when they inevitably change. And in the lucky cases where the
underlying URL haven't changed, all the work that has gone into managing the
infrastructure behind that URL namespace in order for that URL to stay the
same. Updating to remain the same, with apologies to Wendy Chun.

I was reminded of PURLs recently when I happened to
[notice](https://twitter.com/edsu/status/1459502321822482437) a link to
a broken PURL in some [old documentation](https://web.resource.org/rss/1.0/)
about RSS 1.0. In this case Carl fixed the PURL not by updating the PURL to
point at the correct place, but by putting a copy of the document where the
PURL expected it to be.

This got me into looking at how the PURL service worked. As the [Wikipedia
article] sketches out, PURLs have had a variety of implementations over the
years. From the HTML at purl.fdlp.gov it looks like they are running the
Zepheira / 3 Round Stones version--it's not clear to me where one of those
began and the other ended, and if any of that software is open source or not.

In 2016 OCLC and the Internet Archive [announced] that the venerable purl.org
service had moved to the Internet Archive. In the process the software was
completely rewritten (I've heard it's a Python application, but I don't think
the source code has been released). One of the interesting side effects of this
rewrite is that the new PURL server uses IA's backend storage as a kind of
database--and that storage is public.

So every PURL namespace is an item in the [PURL Data Collection]. This
collection contains a couple JSON files that describe the PURL/URL mappings
contained in that namespace as well as who maintains it, and a history of its
changes. So for example the PURL for the Dublin Core Terms namespace is:

[https://purl.org/dc/terms](https://purl.org/dc/terms)

and this IA item contains the metadata for that namespace:

[https://archive.org/details/purl_dc_terms/](https://archive.org/details/purl_dc_terms/)

which really is a s3 like bucket that contains two JSON files:

* [purl_dc_terms_purl.json](https://ia601202.us.archive.org/34/items/purl_dc_terms/purl_dc_terms_purl.json)
* [purl_dc_terms_purl_history.json](https://ia601202.us.archive.org/34/items/purl_dc_terms/purl_dc_terms_purl_history.json)

If you squint a bit the PURL system kind of looks like a static site, in that
the data it uses is all sitting in static files in their *S3-like* storage. Of
course it's not really like a static site because there is a dynamic web
application reading these files, doing the redirects, and no doubt caching
things. Also these seemingly static files are updated when a PURL is edited.
But it's nice that the data is all in JSON files sitting out there for anyone
to look at. In some ways it's not unlike the approach taken by the [w3id]
project, which is basically to [use Git](https://github.com/perma-id/w3id.org)
and Apache to version identifier namespaces. This is fanciful, but both
approaches kind of remind me of the exposed pipes on the Pompidou Center, where
the color of each pipe [represents] a different function (air, electricity,
water, escalators, etc).

<a href="https://commons.wikimedia.org/wiki/File:Centre_Georges-Pompidou_34.jpg"><img src="/images/pompidou.jpg" class="img-responsive"></a>

The w3id approach is nice because you can get all the data with `git clone` on
the command line. Doing the same thing with purl.org is possible, but takes
a little bit more work because you have to use the Internet Archive API to
first get all the items in the [PURL Data Collection] and then go and fetch the
JSON files for all of those items.

I decided to give this a try over in [this] Jupyter notebook. Once you have the
data it's possible to ask some questions that weren't easy to ask before.

How often are new PURL namespaces created?

<img src="/images/purl-namespace-creation.png" class="img-responsive">

A few obvious things to note here are that PURLs started in 1995, and we only
see 2009 on. Also 2009 is off the charts in terms of the number of namespaces
that were created that year. One can only assume that the underlying system was
modified then to start recording when the namespace was created. Things look
a bit more interesting if you ignore the 2009 backlog.

<img src="/images/purl-namespace-creation2.png" class="img-responsive">

Here you can clearly see that more PURL namespaces are being created *after*
the move to the Internet Archive in 2016.

Similarly it's possible to use the history files to see how often namespaces
are being updated *after* they were created.

<img src="/images/purl-namespace-updates.png" class="img-responsive">

This chart tells an opposite story, which is more difficult to read. The
number of namespace updates seems to have dropped off drastically after the
move to the Internet Archive. But the low bar in 2021 is still 1,021 updates,
or like 3 namespace changes per day. I'm not entirely sure what to expect.
Perhaps there were systems tied to the PURL system that got disconnected when
it moved?

Finally one of the more salient questions to ask of this data is how many of
the PURLs still work? This is complex enough for an actual research project and
not just a quick blog. Over in [the notebook] I started by sampling all the
target URLs (N=405,637 n=662). In the process I noticed that it was
oversampling some domains quite a bit like `my.yoolib.net`. So I tried again,
but instead of sampling all the URLs I sampled the PURL namespaces (N=21,894,
n=644) and picked a random URL from each PURL namespace. This seemed to work
better but still seemed to oversample, with hostnames list www.olemiss.edu
showing up quite a bit. It looks like they might create a new PURL namespace
for every finding aid they put up.

Of course, testing whether a URL still works is surprisingly tricky business:
the response could be 200 OK but say Not Found, or it could be a totally
different page (content drift) [@Zittrain:2021]. A server could redirect for
lots of reasons. Sites can be temporarily offline, etc. But this didn't stop me
from writing a pretty simplistic checker (recalling my days at ODU in the 90s)
that allowed me to tally the results for the sample:

<img class="img-responsive" src="/images/purls-status-codes.png">

One thing to note here is that [requests] (the Python HTTP library I used)
automatically followed redirects, so that's why you don't see any 3XX status
codes here. The `???` results are when a TCP/IP error occurred, which from just
scanning the results in the notebook look to largely be the result of a DNS
failure when the hostname no longer can be looked up.

I guess I'll stop here for now. Maybe this little post will whet someone else's
appetite to looking closer at PURL as a web infrastructure. I think it also is
a great example of how *exposed pipes* are useful when building applications
that are meant to be infrastructure. I started out wanting to describe how
these PURLs are showing up as data but it ended up going in a few directions at
once.

One little bit of PURL administrivia that I'll leave you with that since the
PURLs are all part of a [collection] at the Internet Archive they also have an
RSS feed you can use to watch as new namespaces are created:

[https://archive.org/services/collection-rss.php?collection=purl_collection](https://archive.org/services/collection-rss.php?collection=purl_collection)

### References

[created]: https://library.oclc.org/digital/collection/p267701coll28/id/1839
[Federal Depository Library Program]: https://en.wikipedia.org/wiki/Federal_Depository_Library_Program
[GPO]: https://en.wikipedia.org/wiki/United_States_Government_Publishing_Office
[MARCIVE]: https://home.marcive.com/
[856]: https://www.oclc.org/bibformats/en/8xx/856.html
[Persistent Uniform Resource Locator]: https://en.wikipedia.org/wiki/Persistent_uniform_resource_locator
[Wikipedia article]: https://en.wikipedia.org/wiki/Persistent_uniform_resource_locator
[PURL Data Collection]: https://archive.org/details/purl_collection
[this]: https://github.com/edsu/notebooks/blob/master/PURL.ipynb
[the notebook]: https://github.com/edsu/notebooks/blob/master/PURL.ipynb
[announced]: https://cdm15003.contentdm.oclc.org/digital/collection/p15003coll6/id/660
[represents]: https://www.centrepompidou.fr/en/collections/our-building
[collection]: https://archive.org/details/purl_collection?sort=-addeddate
[RSS]: https://archive.org/services/collection-rss.php?collection=purl_collection
[requests]: https://docs.python-requests.org/en/master/index.html
[w3id]: https://github.com/perma-id/w3id.org
