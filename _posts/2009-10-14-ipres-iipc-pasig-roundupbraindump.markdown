---
layout: post
status: publish
published: true
title: ipres, iipc, pasig roundup/braindump
author:
  display_name: ed
  login: ed
  email: ehs@pobox.com
  url: http://www.inkdroid.org
author_login: ed
author_email: ehs@pobox.com
author_url: http://www.inkdroid.org
wordpress_id: 1273
wordpress_url: http://inkdroid.org/journal/?p=1273
date: '2009-10-14 14:15:08 +0000'
date_gmt: '2009-10-14 21:15:08 +0000'
tags: []
comments: []
---
<p>I spent last week in San Francisco attending 3 back-to-back conferences: the <a href="http://www.cdlib.org/iPres/">International Conference on Preservation of Digital Objects</a> (iPRES), <a href="http://web.archive.org/web/20120501044854/http://netpreserve.org/events/index.php">International Internet Preservation Consortium</a> (IIPC),  and the <a href="http://web.archive.org/web/20090830173258/http://sun-pasig.ning.com:80/events/pasig-san-francisco-oct-79">Sun Preservation and Archiving Special Interest Group</a> (PASIG)...thanks to the Library of Congress and to Kesa Summers for letting me go. Also, thanks to the 3 conferences for deciding to co-locate in San Francisco at the same time, which made this sort of tag-team-digital-preservation-event-week possible. I hadn't been to either iPRES, IIPC or PASIG before, so it was a lot of fun being able to take them all in at once...especially since given the nature of my group at the Library of Congress, these are my kind of people.</p>
<p>Each event had a different flavor, but the topic under discussion at each was digital preservation. iPRES focused generally on digital preservation, particularly from a research angle. IIPC also had a bit of a research flavor, but focused more specifically on the practicalities of archiving web content. And PASIG was less research oriented, and much more oriented around building/maintaining large scale storage systems. There was so much good content at these events, that it's kind of impossible to summarize it here. But I thought I would at least attempt to blurrily characterize some of the ideas from the three events that I'm taking back with me.</p>
<p><strong>Forever</strong></p>
<p>Long term digital preservation has many hard problems--so many that I think it is rational to feel somewhat overwhelmed and to some extent even paralyzed. It was important to see other people recognize the big problems of emulation, format characterization/migration, compression -- but continue working on pragmatic solutions, for today. Martha Anderson made the case several times for thinking of digital preservation in terms of 5-10 year windows, instead of <em>forever</em>. The phrase "to get to forever you have to get to 5 years first" got mentioned a few times, but I don't know who said it first. John Kunze brought up the notion of preservation as a "relay", where bits are passed along at short intervals--and how digital curation need to enable these hand offs to happen easily. It came to my <a href="http://twitter.com/cardcc/status/4742006590">attention</a> later that this relay idea is something that Chris Rusbridge <a href="http://www.ariadne.ac.uk/issue46/rusbridge/">written</a> about back in 2006.</p>
<p><strong>Access</strong></p>
<p>On a similar note, Martha Anderson indicated that making bits useful <em>today</em> is a key factor that the National Digital Information Infrastructure and Preservation Program (<a href="http://www.digitalpreservation.gov/">NDIIPP</a>) weighs when making funding decisions. Brewster Kahle in his keynote for IIPC struck a similar note that "preservation is driven by access".  Gary Wright gave an interesting <a href="http://lib.stanford.edu/files/pasig2009sf/pasig2009sf_familysearch_wright.pdf">presentation</a> about how the Church of Latter Day Saints had to adjust the Reference Model for Open Archival Information System (<a href="http://nost.gsfc.nasa.gov/isoas/">OAIS</a>) to enable thousands of concurrent users access to their archive of 3.1 billion genealogical image records. Jennifer Waxman was kind enough to give me a <a href="http://twitter.com/jwax55/status/4685881135">pointer</a> to some <a href="http://www.archives.gov/preservation/conferences/2009/presentations/">work</a> <a href="http://en.wikipedia.org/wiki/Paul_Conway_(professor)">Paul Conway</a> has done on this topic of access driven preservation. The topic of access in digital preservation is important to me, because I work in a digital preservation group at the Library of Congress, working primarily on access applications. We've had a series of pretty intense debates about the role of access in digital preservation ... so it was good to hear the topic come up in San Francisco. In a world where Lots of Copies Keeps Stuff Safe, access to copies is pretty important.</p>
<p><strong>Less is More (More or Less)</strong></p>
<p>Over the week I got several opportunities to hear details from John Kunze, Stephen Abrams, and Margaret Low about the California Digital Library's notion of <a href="http://www.cdlib.org/inside/diglib/">curation micro-services</a>, and how they enable digital preservation efforts at CDL. Several <a href="http://web.archive.org/web/20100218060222/http://lackoftalent.org:80/michael/blog/2009/09/27/exploring-curation-micro-services/">folk</a>s in my group at LC have been taking a close look at the CDL specifications recently, so getting to hear about the specs, and even see some implementation demos from Margaret was really quite awesome. The specs are interesting to me because they seem to be oriented around the fact that our digital objects ultimately reside on some sort of hierarchical file-system. Fileystem APIs are fairly ubiquitous. In fact, as David Rosenthal has <a href="http://vimeo.com/5407401">pointed out</a>, some file systems are even <a href="http://www.ieee.org/portal/pages/about/awards/bios/2009_Recips/2009rbjinfo_mckusick.html">designed</a> to resist change. As Kunze said at PASIG in his talk <a href="http://lib.stanford.edu/files/pasig2009sf/pasig-2009-pods.pdf">Permanent Objects, Evolving Services, and Disposable Systems: An Emergent Approach to Digital Curation Infrastructure</a></p>
<blockquote><p>
What is the thinnest smear of functionality that we can add to the filesystem so that it can act as an object storage system?
</p></blockquote>
<p>Approaches to building digital repository software thus far have been primarily aimed at software stacks (dspace, fedora, eprints) which offer particular services, or service frameworks. But the reality is that these systems come and go, and we are left with the bits. Why don't we try to get the bits in shape so that they can be handed off easily in the relay from application to application, filesystem to filesystem? What is nice about the micro-services approach is that:</p>
<ul>
<li>The services are compose-able, allowing digital curation activities to be emergent, rather than imposed by a pre-defined software architecture. Since I've been on a bit of a functional programming kick lately, I see compose-ability as a <a href="http://web.archive.org/web/20090803123913/http://www.cs.chalmers.se:80/~rjmh/Papers/whyfp.html">pretty</a> <a href="www.stanford.edu/class/cs242/readings/backus.pdf">big</a> <a href="http://www.joelonsoftware.com/items/2006/08/01.html">win</a>.</li>
<li>The services are defined by short specifications, not software--so they are ideas instead of implementations. The specifications are clearly guided by ease of implementation, but ultimately they could be implemented in a variety of languages, and tools. Having a 2-3 page spec that defines a piece of functionality, and can be read by a variety of people, and implemented by different groups seems to be an ideal situation to strive for. </li>
</ul>
<p><strong>Everything Else Is Miscellaneous</strong></p>
<p>Like I said, there was a ton of good content over the week...and it seems somewhat foolhardy to try to summarize it all in a single blog post. I tried to summarize the main themes I took home with me on the plane back to DC...but there were also lots of nuggets of ideas that came up in conversation, and in presentations that I want to at least jot down:</p>
<ul>
<li>While archival storage may not be best served by <a href="http://web.archive.org/web/20120513124017/http://hadoop.apache.org/common/docs/current/hdfs_design.html">HDFS</a>, jobs like <a href="http://web.archive.org/web/20110114005808/http://www.netpreserve.org/events/active_solutions/4_Holden_Here%20be%20Dragons.ppt">virus scanning huge web crawls</a> are well suited to distributed computing environments like <a href="http://hadoop.apache.org/">Hadoop</a>. We need to be able to operate at this scale at loc.gov.
</li>
<li>In Cliff Lynch's summary wrap up for PASIG he indicated that people don't talk so much about what we do when the inevitable happens, and bits are lost. The digital preservation community needs to share more statistics on bit loss, system failure modes, and software design patterns that let us build more sustainable storage systems.</li>
<li>Dave Tarrant's presentation on <a href="http://eprints.ecs.soton.ac.uk/17556/">Where the Semantic Web and Web 2.0 meet format risk management: P2 registry</a> was a welcome revelation about the intersection of my interest in linked data and digital preservation. His presentation of the <a href="http://www.nationalarchives.gov.uk/pronom/">PRONOM</a> format registry as <a href="http://web.archive.org/web/20120607071216/http://p2-registry.ecs.soton.ac.uk:80/">linked data</a>, and Kevin De Vorsey's talk about <a href="http://lib.stanford.edu/files/pasig2009sf/PASIG_2009_DeVorsey.pdf">Obsolescence, Risk Management, and Preservation Planning at the National Library of New Zealand</a> made me think that it might be interesting to explore how the LC's <a href="http://www.digitalpreservation.gov/formats/">Digital Formats</a> website could be delivered as linked data, and linked to something like PRONOM. David Pearson also <a href="http://web.archive.org/web/20120507072533/http://netpreserve.org/events/presenters.php">suggested</a> that collaborative wiki-spaces could be used by digital format specialists to collect information...which got me thinking of how a <a href="http://semantic-mediawiki.org/wiki/Semantic_MediaWiki">semantic media wiki</a> instance could be used in conjunction with Tarrant's ideas. How easy would it be to use the web to build a distributed network of preservation information, as opposed to some p2p solution?</li>
<li>I want to learn more about the (w)arc data format, and perhaps contribute to some of the existing <a href="http://code.google.com/p/warc-tools/">code</a> <a href="http://web.archive.org/web/20101123161017/http://code.google.com:80/p/search-tools/">bases</a> for working w/ (w)arc. I'm particularly interested in using harvesting tools and WARC to preserve linked data...which I believe some of the Sindice folks have worked on for their <a href="http://sindice.com/developers/bot">bot</a>.</li>
<li>It's long since time I understood how LOCKSS works as a technology. It was mentioned as the backbone of <a href="http://www.ohloh.net/p/dpp-lockss">several</a> <a href="http://www.metaarchive.org/">projects</a> <a href="http://www.clockss.org/clockss/Home">during</a> the week. I even overheard some talk about establishing rogue LOCKSS networks, which of course piqued my interest even more.</li>
<li>It would be fun to put a jython or jruby web front end on <a href="http://sourceforge.net/projects/droid/">DROID</a> for format identification, but it seems that Carol Chou of the Florida Center for Library Automation has already <a href="http://listserv.loc.gov/cgi-bin/wa?A2=ind0910&L=pig&T=0&P=55">done something similar</a>. Still, it would be neat to at least try it out, and perhaps have it conneg to Dave's <a href="http://web.archive.org/web/20120607071216/http://p2-registry.ecs.soton.ac.uk:80/">P2</a> registry or <a href="http://www.nationalarchives.gov.uk/pronom/">PRONOM</a>.
</li>
</ul>
<p>Ok, braindump complete. Thanks for reading this far!</p>
