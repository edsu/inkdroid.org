---
layout: post
status: publish
published: true
title: On Archiving Tweets
author:
  display_name: ed
  login: ed
  email: ehs@pobox.com
  url: http://www.inkdroid.org
author_login: ed
author_email: ehs@pobox.com
author_url: http://www.inkdroid.org
wordpress_id: 8020
wordpress_url: http://inkdroid.org/journal/?p=8020
date: '2014-08-31 07:55:48 +0000'
date_gmt: '2014-08-31 14:55:48 +0000'
tags:
- preservation
- twitter
- business
comments:
- id: 87160
  author: laurelrusswurm.wordpress.com/
  author_email: ''
  author_url: http://laurelrusswurm.wordpress.com/
  date: '2014-09-03 09:53:53 +0000'
  date_gmt: '2014-09-03 16:53:53 +0000'
  content: |
    TOSes already carry far much more power than they ought to, adding more is not a good idea.
    You must remember that copyright is really just a state imposed monopoly, and as such it works differently around the world.   Just because the Twitter TOS requires us to license or even assign our copyright, even after we have assigned our copyright to Twitter, we Canadians retain our moral rights under law, <em>which gives <b>us</b> a say in what <b>you</b> do with it.</em>
    I very strongly disagree with your conclusion that:
    <blockquote>...(the research community) need to manage access to this data so that it’s not just out there for anyone to use..."</blockquote>
    The data in archives needs to be OPEN data.  Why on earth should institutional archives be able to store my data, and what entitles researchers use my data, while preventing others &mdash; including <em>me</em> &mdash; from having the same access?
    Certainly there are privacy issues, but rather than taking the paternalistic view that researchers (or worse, <em>institutions</em>) are somehow better equipped (<em>morally? ethically? intellectually?</em>) than the public to manage <em>our</em> personal data &mdash; presumably because most of the public continues to be ignorant of the serious consequences of private information made public &mdash; why not help educate people instead?
    If more people understood privacy issues, it would be easier to deal with breaches or concerns.
    Despite legal idiocy, no one has the "right to be forgotten."  Setting aside the problems of doublespeak and thoughtcrime inherent in such a dangerous legal precedent, the fact remains: <b>the only way privacy can be protected is by keeping private information private</b>.
    People will continue to be deluded into believing Twitter or Facebook privacy settings will make it "private," so long as credence is given to the fairy tale that privacy can be magically restored after publication.  <b>Instead help people understand anything they post on the Internet can never again be private because the Internet is a public space.</b>.
- id: 87161
  author: ed
  author_email: ehs@pobox.com
  author_url: http://www.inkdroid.org
  date: '2014-09-03 10:33:18 +0000'
  date_gmt: '2014-09-03 17:33:18 +0000'
  content: |
    <p>Thanks for your comment. I really sympathize with your position. Actually, you've channeled my inner voice on this matter pretty well :-)</p>
    <p>It's a bit of a gray area, but I believe <a href="https://twitter.com/tos" rel="nofollow">Twitter's ToS</a> do not claim copyright over your tweets:</p>
    <blockquote>
      <p>Twitter has an evolving set of rules for how ecosystem partners can interact with your Content. These rules exist to enable an open ecosystem with your rights in mind. But what’s yours is yours – you own your Content (and your photos are part of that Content).</p>
    </blockquote>
    <p>I think it's a gray area because even though Twitter does not claim to own your content, they also don't say whether it is ownable. I guess whether a tweet can be copyrighted is open for debate, at least in some circles. Do a Google search on "is a tweet copyrightable" and get lost for a while :-)</p>
    <p>Be that as it may, I think you are spot on in saying that users of social media need to understand that they should be very careful about the personal data that they put "into the cloud". It is something I talk to my kids about it, and I'm sure it's a familiar conversation everywhere. So a new generation of more savvy social media users aka "the public" will soon take center stage.</p>
    <p>One other thing to keep in mind is that traditionally, when archives are given collections, there is normally a <a href="http://www2.archivists.org/publications/brochures/deeds-of-gift" rel="nofollow">deed of gift</a> that stipulates certain conditions under which the content can be used. Sometimes these deeds restrict access to particular content, or require approval from the record creators, or keep the content closed for a period of time. These deeds of gift can vary from collection to collection. For example <a href="http://blogs.loc.gov/loc/files/2010/04/LOC-Twitter.pdf" rel="nofollow">here</a> is the deed of gift of the Twitter data to the Library of Congress. Not all information in archives is public. I personally think archives that make sharing information publicly on the Web a priority will be the ones that thrive. One needs to look no further than the Wikipedia success story to see that.</p>
    <p>Now in the case of my particular collection of Ferguson tweets, I used Twitter's API to generate the dataset. Yes, it was all information put on the public Web by users. But if I am going to be a responsible actor I should try to at least abide by the ToS for the API should I. However I also have responsibilities as an archivist, in particular the <a href="http://www2.archivists.org/statements/saa-core-values-statement-and-code-of-ethics" rel="nofollow">SAA Code of Ethics</a> which says:</p>
    <blockquote>
      <p>Archivists promote and provide the widest possible accessibility of materials, consistent with any mandatory access restrictions, such as public statute, donor contract, business/institutional privacy, or personal privacy. Although access may be limited in some instances, archivists seek to promote open access and use when possible. Access to records is essential in personal, academic, business, and government settings, and use of records should be both welcomed and actively promoted. Even individuals who do not directly use archival materials benefit indirectly from research, public programs, and other forms of archival use, including the symbolic value of knowing that such records exist and can be accessed when needed.</p>
    </blockquote>
    <p>I am hopeful that we will see emerging consensus in the archival community about how to balance the needs of businesses and their ToS, the rights of individuals who put content into the public space of the Web, and the needs of researchers who would like to use these collections.</p>
    <p>I strongly sympathize with your main point that archives need to focus and give preference to open content. If the archival profession is to continue in its current form I think it needs to get its donors thinking in terms of Creative Commons license, and how their content can be made part of the Web, when the time comes.</p>
- id: 87163
  author: Archiving the web during the conflict and protest in Ferguson, MO | Learn
    More
  author_email: ''
  author_url: http://aitlearnmore.archive.org/2014/09/03/archiving-the-web-during-the-conflict-and-protest-in-ferguson-mo/
  date: '2014-09-03 11:08:56 +0000'
  date_gmt: '2014-09-03 18:08:56 +0000'
  content: |
    [&#8230;] has extracted the top 50 links mentioned in these archived tweets (see also his follow-up post, “On Archiving Tweets”). We have added these top 50 links to the Archive-It collection and will continue to collaborate [&#8230;]
- id: 87165
  author: Archiving the web during events in Ferguson, MO | Learn More
  author_email: ''
  author_url: https://aitlearnmore.archive.org/2014/09/03/archiving-the-web-during-the-conflict-and-protest-in-ferguson-mo/
  date: '2014-09-04 11:40:07 +0000'
  date_gmt: '2014-09-04 18:40:07 +0000'
  content: |
    [&#8230;] in the first 50,000 tweets from the evening on August 10th (see also his follow-up post, “On Archiving Tweets”). We  added these 50 links to the Archive-It collection and will continue to collaborate with [&#8230;]
- id: 87171
  author: 'Editors&#8217; Choice: On Archiving Tweets | Digital Humanities Now'
  author_email: ''
  author_url: http://digitalhumanitiesnow.org/2014/09/editors-choice-on-archiving-tweets/
  date: '2014-09-15 10:51:57 +0000'
  date_gmt: '2014-09-15 17:51:57 +0000'
  content: |
    [&#8230;] On Archiving Tweets [&#8230;]
---

<p><img src="http://inkdroid.org/images/webpresmed/package.png" style="width: 200px; float: left; margin-right: 10px;" /></p>
<p>After my last <a href="http://inkdroid.org/journal/2014/08/30/a-ferguson-twitter-archive/">post</a> about collecting 13 million Ferguson tweets <a href="http://twitter.com/liblaura">Laura Wrubel</a> from George Washington University's <a href="http://social-feed-manager.readthedocs.org/">Social Feed Manager</a> project <a href="https://twitter.com/liblaura/status/505925215852191745">recommended</a> looking at how <a href="http://twitter.com/vphill">Mark Phillips</a> made his <a href="http://digital.library.unt.edu/ark:/67531/metadc304853/m1/">Yes All Women</a> collection of tweets available in the <a href="http://digital.library.unt.edu/">University of North Texas Digital Library</a>. <em>By the way, both are awesome projects to check out if you are interested in how access informs digital preservation.</em></p>
<p>If you take a look you'll see that only the Twitter ids are listed in the data that you can download. The full metadata that Mark collected (with <a href="http://github.com/edsu/twarc">twarc</a> incidentally) doesn't appear to be there. Laura knows from her work on the <a href="http://social-feed-manager.readthedocs.org/">Social Feed Manager</a> that it is fairly common practice in the research community to only openly distribute lists of Tweet ids instead of the raw data. I believe this is done out of concern for Twitter's <a href="https://dev.twitter.com/terms/api-terms">terms of service</a> (1.4.A):</p>
<blockquote>
<p>If you provide downloadable datasets of Twitter Content or an API that returns Twitter Content, you may only return IDs (including tweet IDs and user IDs).</p>
<p>You may provide spreadsheet or PDF files or other export functionality via non­-programmatic means, such as using a "save as" button, for up to 100,000 public Tweets and/or User Objects per user per day. Exporting Twitter Content to a datastore as a service or other cloud based service, however, is not permitted.</p>
</blockquote>
<p>There are privacy concerns here (redistributing data that users have chosen to remove). But I suspect Twitter has business reasons to discourage widespread redistribution of bulk Twitter data, especially now that they have <a href="https://blog.twitter.com/2014/twitter-welcomes-gnip-to-the-flock">bought</a> the social media data provider <a href="http://gnip.com">Gnip</a>.</p>
<p>I haven't really seen a discussion of this practice of distributing Tweet ids, and its implications for research and digital preservation. I see that the <a href="http://www.icwsm.org/">International Conference on Weblogs and Social Media</a> now have a <a href="http://www.icwsm.org/2014/datasets/datasets/">dataset service</a> where you need to agree to their "Sharing Agreement", which basically prevents re-sharing of the data.</p>
<blockquote>
<p>Please note that this agreement gives you access to all ICWSM-published datasets. In it, you agree not to redistribute the datasets. Furthermore, ensure that, when using a dataset in your own work, you abide by the citation requests of the authors of the dataset used.</p>
</blockquote>
<p>I can certainly understand wanting to control how some of this data is made available, especially after the debate after <a href="http://inkdroid.org/journal/2014/08/14/one-big-archive/">Facebook's Emotional Contagion Study</a> went public. But this does not bode well for digital preservation where lots of copies keeps stuff safe. What if there were a standard license that we could use that encouraged data sharing among research data repositories? A viral license like the <a href="https://en.wikipedia.org/wiki/GNU_General_Public_License">GPL</a> that allowed data to be shared and reshared within particular contexts? Maybe the <a href="https://creativecommons.org/licenses/by-nc/2.0/">CC-BY-NC</a>, or is it too weak? If each tweet is copyrighted by the person who sent it, can we even license them in bulk? What if Twitter's terms of service included a research clause that applied to more than just Twitter employees, but to downstream archives?</p>
<h2>Back of the Envelope</h2>
<p>So if I were to make the ferguson tweet ids available, to work with the dataset you would need to refetch the data using the Twitter API, one tweet at a time. I did a little bit of <a href="https://dev.twitter.com/docs/rate-limiting/1.1">reading</a> and poking at the Twitter API and it appears an access token is limited to 180 requests every 15 minutes. So how long would it take to reconstitute 13 million Twitter ids?</p>
<pre><code>13,000,000 tweets / 180 tweets per interval = 72,222 intervals
72,222 intervals * 15 minutes per interval =  1,083,330 minutes
</code></pre>
<p><a href="http://www.wolframalpha.com/input/?i=1%2C083%2C330+minutes">1,083,330 minutes</a> is <strong>two years</strong> of constant accesses to the Twitter API. Please let me know if I've done something conceptually/mathematically wrong.</p>
<p><em>Update: it turns out the <a href="https://dev.twitter.com/docs/api/1.1/get/statuses/lookup">statuses/lookup</a> API call can return full tweet data for up to 100 tweets per request. So a single access token could fetch about 72,000 tweets per hour (100 per request, 180 requests per 15 minutes) ... which only amounts to 180 hours, which is just over a week. James Jacobs rightly <a href="https://twitter.com/freegovinfo/status/506600456659812352">points out</a> that a single application could use multiple access tokens, assuming users allowed the application to use them. So if 7 Twitter users donated their Twitter account API quota, the 13 million tweets could be reconstituted from their ids in roughly a day. So the situation is definitely not as bad as I initially thought. Perhaps there needs to be an app that allows people to donate some of the API quota for this sort of task? I wonder if that's allowed by Twitter's ToS.</em></p>
<p>The big assumption here is that the Twitter API continues to operate as it currently does. If Twitter changes its API, or ceases to exist as a company, there would be no way to reconstitute the data. But what if there were a functioning Twitter archive that could reconstitute the original data using the list of Twitter ids...</p>
<h2>Digital Preservation as a Service</h2>
<p>I've hesitated to write about LC's Twitter archive while I was an employee. But now that I'm no longer working there I'll just say I think this would be a perfect experimental service for them to consider providing. If a researcher could upload a list of Twitter ids to a service at the Library of Congress and get them back a few hours, days or even weeks later, this would be much preferable to managing a two year crawl of Twitter's API. It also would allow an ecosystem of Twitter ID sharing to evolve.</p>
<p>The downside here is that all the tweets are in one basket, as it were. What if LC's Twitter archiving program is discontinued? Does anyone else have a copy? I wonder if Mark kept the original tweet data that he collected, and it is private, available only inside the UNT archive? If someone could come and demonstrate to UNT that they have a research need to see the data, perhaps they could sign some sort of agreement, and get access to the original data?</p>
<p>I have to be honest, I kind of loathe idea of libraries and archives being gatekeepers to this data. Having to decide what is valid research and what is not seems fraught with peril. But on the flip side Maciej has <a href="http://idlewords.com/bt14.htm">a point</a>:</p>
<blockquote>
<p>These big collections of personal data are like radioactive waste. It's easy to generate, easy to store in the short term, incredibly toxic, and almost impossible to dispose of. Just when you think you've buried it forever, it comes leaching out somewhere unexpected.</p>
<p>Managing this waste requires planning on timescales much longer than we're typically used to. A typical Internet company goes belly-up after a couple of years. The personal data it has collected will remain sensitive for decades.</p>
</blockquote>
<p>It feels like we (the research community) need to manage access to this data so that it's not just out there for anyone to use. Maciej's essential point is that businesses (and downstream archives) shouldn't be collecting this behavioral data in the first place. But what about a tweet (its metadata) is behavioural? Could we strip it out? If I squint right, or put on my NSA colored glasses, even the simplest metadata such as who is tweeting to who seems behavioral.</p>
<p>It's a bit of a platitude to say that social media is still new enough that we are still figuring out how to use it. Does a legitimate <a href="https://en.wikipedia.org/wiki/Right_to_be_forgotten">right to be forgotten</a> mean that we forget everything? Can businesses blink out of existence leaving giant steaming pools of informational toxic waste, while research institutions aren't able to collect and preserve small portions as datasets? I hope not.</p>
<p>To bring things back down to earth, how should I make this Ferguson Twitter data available? Are a list of tweet ids the best the archiving community can do, given the constraints of Twitter's Terms of Service? Is there another way forward that addresses very real preservation and privacy concerns around the data? Some archivists may cringe at the cavalier use of the word "archiving" in the title of this post. However, I think the issues of access and preservation bound up in this simple use case warrant the attention of the archival community. What archival practices can we draw and adapt to help us do this work?</p>
