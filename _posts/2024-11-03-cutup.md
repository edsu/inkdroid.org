---
layout: post
title: Cut-ups and LLMs
tags:
- artificial-intelligence
- poetry
- creativity
- politics
- art
---

If language is a virus what are LLMs?

I've had this kinda random notion about [Large Language Models](https://en.wikipedia.org/wiki/Large_language_model) (LLM) and the [Cut-up technique] rumbling around in my brain for the past year. Unless you've been living in a cave I'm guessing you already know about LLMs. You probably already know about Cut-ups too, but just in case here is how Burroughs and Gysin describe this creativity tool [@Burroughs:1982, p. 34]:

> Writing is fifty years behind painting. I propose to apply the painters’
> techniques to writing; things as simple and immediate as collage or montage.
> Cut right through the pages of any book or newsprint… lengthwise, for
> example, and shuffle the columns of text. Put them together at hazard and
> read the newly constituted message. Do it for yourself. Use any system which
> suggests itself to you. Take your own words or the words said to be “the very
> own words” of anyone else living or dead. You’ll soon see that words don’t
> belong to anyone. Words have a vitality of their own and you or anybody else
> can make them gush into action.

<section style="display: flex;">

<figure>
<a href="/images/cutup-01.jpg">
<img class="img-fluid" src="/images/cutup-01.jpg">
</a>
<figcaption>p. 34 of The Third Mind</figcaption>
</figure>

<figure>
<a href="/images/cutup-02.jpg">
<img class="img-fluid" src="/images/cutup-02.jpg">
</a>
<figcaption>p. 35 of The Third Mind</figcaption>
</figure>

</section>

Burroughs famously used this technique in his [Nova Trilogy] (and elsewhere) to mix together the works of other authors (Shakespeare, Rimbaud, Kerouac, Genet, Kafka, Eliot, Conrad, ...). It has since been widely used as a creativity tool, apparently by musicians like [David Bowie, Kurt Cobain and Thom Yorke](https://www.openculture.com/2015/02/bowie-cut-up-technique.html). The purpose of this hack isn't simply to come up with new ideas, but to dismantle discursive systems of control:

> The Burroughs machine, systematic and repetitive, simultaneously disconnecting and reconnecting---it disconnects the concept of reality that has been imposed on us and the plugs normally dissociated zones into the same sector--eventually escapes from the control of its manipulator; it does so in that it makes it possible to lay down a foundation of an unlimited number of books that end by reproducing themselves. [@Burroughs:1982, p. 17]

So what do LLMs and Cut-ups have to do with each other?

One superficial way of thinking about LLMs is as the ultimate cut-up machine. LLMs are built by taking a massive amount of content from the Web, chopping it up into words (tokens), and then creating a neural network that represents the likelihood of one token following another. This allows new text to be generated word by word given an initial sequence, or prompt. Similar to the cut-up, it's no longer possible to attribute LLM generated text to a particular author or authors. The very idea of authorship and attribution is completely dissolved in the model.

However the big difference with LLMs is that they are optimized for [predicting the next likely word](https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f), given an initial sequence of words. An LLM is ultimately a statistical representation of likely text. The Cut-up on the other hand is specifically designed to *break* the typical associations of words, but without totally obscuring where those words came from.

LLMs discipline communication, and routinize language in an attempt to simulate meaningful text. Cut-ups intentionally break word associations in order to reveal non-obvious, possibly absurd, latent meanings. LLMs are ultimately tools for normalization and control through language, and the Cut-up is a tool for wresting back control, by peeking inside the discursive machinery of language.

I was reminded of this today when I ran across a lovely short paper by [Max Kreminski](https://mkremins.github.io/) entitled [Computational Poetry is Lost Poetry](https://dl.acm.org/doi/10.1145/3686169.3686179) which he presented at the [Halfway to the Future](https://www.halfwaytothefuture.net/2024/) conference ([open-access Proceedings](https://dl.acm.org/doi/proceedings/10.1145/3686169)) recently.

In this paper he draws a comparison between [Found Poetry](https://en.wikipedia.org/wiki/Found_poetry), where poetry is discovered in everyday use of language, and LLMs "whose central purpose is to arrange units of language, without fully understanding them, in combinations that can later be found to be poetry". He calls this LLM generated text "Lost Poetry". Of course not everyone using LLMs is trying to write poetry, or think creatively, so this analogy doesn't totally work for all LLM use cases. But he goes on to make some insightful observations about the flaws of generative AI:

> I argue that machines are often usefully creative because they fail to see things completely as humans do: their oversights and inabilities lead them to mix human-like with non-human-like creative decisions in unanticipated ways, and thereby to supply human creators with ideas that they otherwise never would have considered. Somewhat counter-intuitively, then, I suggest that a dogged pursuit of perfect overlap between human and machine understanding of aesthetic domains may in fact inhibit the usefulness of machines as generators of unexpected inputs to the human creative ecosystem.

The flaws that we see in these generative systems is what makes them useful, and the quest to build bigger and bigger models that better model "reality" works at cross purposes with their use in creative endeavors. It's the glitches that provide value. He goes on to say:

> ... the design of novel computationally creative systems could be guided in part by a deliberate choice of what to make invisible to the machine. By selectively limiting the machine’s capacity to take certain facets of human aesthetic perception into account, we can produce different kinds of losers that can help to break us out of familiar patterns toward new techniques of expressive communication.

This is a provocative idea I think, that it's the limitations that we build (intentionally or not) into computational systems that make them legible to us humans. These limitations help define or set them apart the tools from one another. Just as Cut-ups engineer for the unexpected, and transgress predictable narrative structures, these LLM generated "losers" have more potential for creative thought because they are errors. Maybe this is one move too far, but there seems to be some parallels here to *seamful* design, where "strategic revelation of complexity, error, or backgrounded tasks" provide value instead of distraction [@Inman:2019].

But perhaps Kreminski, as a chief scientist at a generative AI company, is trying very hard to find value in these statistical models that ultimately drive out and exploit creativity. They do this by disciplining language by normalizing our words to fit a the types of words found on the World Wide Web at a particular point in time. I wish him well in his efforts to make these models smaller, more quirky, and more useful for actual artists--instead of larger and smoother for people who don't want to employ human artists anymore.

I do wonder, what would it look like if LLMs worked more like Cut-ups, where we got unfamiliar juxtapositions and the sources weren't completely obfuscated/concealed?

### References

[Nova Trilogy]: https://en.wikipedia.org/wiki/The_Nova_Trilogy
[Cut-up technique]: https://en.wikipedia.org/wiki/Cut-up_technique

