---
layout: post
title: The Shallows
tags:
- reading
- web
- artificial-intelligence
---

I didn't read Nicholas Carr's [The Shallows] when it came out in 2011. I was working as a software engineer at the Library of Congress helping [put historical newspapers] on the web, and felt indicted by the thesis of the book, which, it seemed to me, boiled down to the idea that the Web was making us stupid. I had built a career around web technology and I wasn't interested in reading anything that questioned whether the web was a net positive.

Recently, in light of all that's going on with AI at the moment, and [my] [critical] [takes] on it, I thought perhaps I had dismissed Carr's book too quickly. Just how long has this project been going on? Did Carr see where things were headed? I mentioned the idea, and a few other people [agreed] to do a popup bookclub about it.

I'm glad I did get around to reading it finally. I got Carr wrong, he was (is?) a fan of the web, just like I was at the time. But noticing a decline in his ability to focus for long periods prompted him to research and write The Shallows. He draws on the history of the book, media studies and the history of technology more generally to illustrate how technologies like clocks, maps, writing, and the book shaped how we remember and thought itself. In the second half of the book he talks about how the invention of the [universal machine] (the computer) has effectively absorbed prior forms of media into computers, as hypermedia. I don't think Carr explicitly mentions the concept of *Remediation* [@Bolter:1996] here, but I thought it was interesting to see how he connects media to the computer's ability to simulate other machines. He also brings in neurology and psychology research literature to explain how different phases of memory formation are disturbed by rapid attention shifts that browsing the web affords:

> The Web provides a convenient and compelling supplement to personal memory, but when we start using the Web as a substitute for personal memory, bypassing the inner processes of consolidation, we risk emptying our minds of their riches. [@Carr:2011, 192]

I thought this line of critique was especially interesting in light of the recent popularization of AI in the form of "chatting" with Large Language Models (LLM) like ChatGPT. ChatGPT's interface provides a smooth surface where you conversationally interact with a computer to obtain information. It doesn't give you citations, or links to things on the web to consult. Instead it gives you an answer, and you either continue the clarify what you are looking for, move on to something else or decide to stop. You don't see a list of search results, which you need to click on and move laterally into, to see if they contain the answer to your question. These documents could have distracting design components, ads or other boilerplate. You don't need to read the linked documents. ChatGPT seductively bypasses all that and you read *The Answer*. Much to my dismay, it seemed like perhaps the affordances of ChatGPT style interaction may not present the same problems as classic web navigation, at least in terms of distractions that lead to quick context shifts, and disturb our ability to form memories? I imagine there are hordes of education and pyschology researchers looking into this as a type, or they already have.

It was bit surreal reading the detailed descriptions in the final chapters about how neurons store memories through repetitive training ... which echo the same language that is used to talk about deep learning today. These are powerful metaphors that have been deployed. Almost anticipating recent developments in AI, Carr ends the book talking about the goals of classic AI, and specifically the warnings of [Joseph Weizenbaum] in his book [Computer Power and Human Reason].

> What Makes us most human, Weizenbaum had come to believe, is what is least computable about us--the connections between our mind and our body, the experiences that shape our memory and our thinking, our capacity for emotion and empathy. The great danger we face as we become more intimately involved with our computers--as we come to experience more of our lives through the disembodied symbols flickering across our screens--is that we'll begin to lose our humanness, to sacrifice the very qualities that separate us from machines. The only way to avoid that fate, Weizenbaum wrote, is to have the self-awareness and the courage to refuse to delegate to computers the most human of our mental activities and intellectual pursuits, particularly "tasks that demand wisdom". [@Carr:2011, 207-208].

Weizenbaum was the creator the original chatbot [Eliza]. I didn't realize that his experience of seeing how ELIZA was used prompted him to critique the goals of Artificial Intelligence community. Maybe it's not surprising because according to Carr Weizenbaum's book was trashed by leaders in the computer science community at the time. Perhaps digging up a copy of Weizenbaum's book might be interesting reading in light of AI's resurgence now.

The Shallows had lots of citations to current states of affairs, demographics and statistics that gave authority to Carr's arguments. But these got a little bit repetitive at times, but the drudgery drives the points home I guess. It is striking reading it 13 years later how much the web has changed.

In discussing the technologies of literacy and the book I felt a little bit like Carr's would have benefited at looking at the book and literacy as instruments of power, that mobilized colonialism and capitalist extraction. I found myself thinking a lot about Bernard Stiegler while reading The Shallows, especially for the idea that writing and computational devices are memory prostheses, and that they are a pharmakon (contain both a remedy and a poison). A quick Kagi search and I can see Stiegler had a [sequence of lectures] about Carr. So I guess they knew of each other?

Overall I enjoyed The Shallows, even though I'm still working as a web developer. Nowadays I'm explicitly interested in the web's role in memory practices, and what can be done from an architecture and design perspective to work against the grain of the web's most pernicious features. There are some good threads to tug on in The Shallows.

### References

[my]: https://inkdroid.org/2024/03/12/ai/
[critical]: https://inkdroid.org/2024/02/21/magic/
[takes]: https://inkdroid.org/2023/06/04/copilot/
[agreed]: https://social.coop/@edsu/111980705994284281
[Joseph Weizenbaum]: https://en.wikipedia.org/wiki/Joseph_Weizenbaum
[Computer Power and Human Reason]: https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason
[Eliza]: https://en.wikipedia.org/wiki/ELIZA 
[sequence of lectures]: https://terenceblake.wordpress.com/2012/06/24/translations-of-bernard-stieglers-seminar/
[The Shallows]: https://en.wikipedia.org/wiki/The_Shallows_(book)
[put historical newspapers]: https://chroniclingamerica.loc.gov
[universal machine]: https://en.wikipedia.org/wiki/Universal_Turing_machine
