---
layout: post
title: We Check Its Work
tags:
- ai
- hci
---

<figure>
  <a href="https://en.wikipedia.org/wiki/Makatea#/media/File:Makatea2.JPG">
  <img class="img-fluid" src="/images/makatea.jpg">
  </a>
  <figcaption>NASA astronaut image of <a href="https://en.wikipedia.org/wiki/Makatea#/media/File">Makatea Island</a></figcaption>
</figure>

[Richard Powers]' [Playground] is a lot of things, but for me it seemed to be very much a meditation on the near-future (or perhaps present) of [Large Language Models] like ChatGPT, and how they fit into our culture and politics. I won't give away any spoilers (it is worth a read!), but one moment in the story has been stuck in my head, due to some things going on at work, so I thought I'd make a note here to get it out of my head.

Near the end of the novel a group of people living on the island of [Makatea] are trying to decide whether they want to accept a proposal from a consortium of corporations to develop, and thus greatly transform, their island home. Only 50 or so people live on the island, and they have decided to vote on it.

In order to help the Makateans decide how to vote the consortium of corporations provided the island's inhabitants with exclusive access to a 3rd generation Large Language Model called Profunda, which operates much like ChatGPT does today. Users can engage with it in conversation using their voice, and inquire about how the proposed development will impact the island. Profunda has access to confidential materials related to the consortium and its detailed plans. It was built on top of a foundation model that was assembled from a massive harvest of content from the World Wide Web.

In this short segment below some of the characters are discussing how to vote based on the information they learned by "chatting" with Profunda:

<blockquote>
"I don’t know how to vote. I don’t even know who this consortium is! People always say, ‘Follow the money.’ I’m supposed to vote this up or down, without even knowing who exactly is paying for this pilot program or what they stand to gain by this . . . seasteading."

Pockets of applause followed the comment, suggesting that the priest was not the only one still at sea.

Manutahi Roa was baffled by the objection. He waved a dossier of printouts in the air. "You should have asked Profunda. I did!"

"But how can I trust him?" the priest shouted back. "The consortium made him!"

Neria Tepau, the postmistress, shot to her feet. "Exactly! We should have been researching for ourselves, these last ten days. We have phones. We have a cell tower. We can search every web page in the world. Instead, we’re relying on this construction, this . . . thing to spoon-feed us!"

"Neria!" Wen Lai’s objection sounded tired. "A search engine spoon-feeds us, too."

"So letting this thing do the work and making a biased summary is somehow better than me going through the pages myself?"

Hone Amaru laughed. "This thing has read a hundred billion pages. How many can you read, in ten days?"

"It’s the ten days that is the crime! We’re being railroaded!" The words cracked in Puoro’s throat. Patrice put his arm around his partner’s shoulders.

The Queen stood up and the room settled down. "People. Friends. Sisters. Brothers. We’re letting the Popa’ā make us as crazy as they are!"

This observation was met by near-universal applause. Even the mayor collected himself and clapped.

"It’s easy," the Queen went on. "We ask who is paying. It tells us. And then, as Madame Martin would say, we check its work" She looked to the schoolteacher, who held both her thumbs high in the air. The assembly broke into a new round of applause.

When the cheers settled, the mayor said, "Profunda. Please give us short biographies for the five biggest investors in this seasteading consortium."
</blockquote>

This scene was striking to me, because The Queen's statement seemed kinda obvious, at least on the surface. How do we know if we can trust generative AI? *We check its work.* Checking the work in this case seems doable, I guess. They were asking who were the biggest investors in the consortium. The assumption being that it was easy for them to find sources to check for verification.

At some level, triangulating fact claims, and reproducibility are how knowledge is built. But it requires work. It takes time. It can sometimes require specialized expertise. As Generative AI tools get used to accelerate "knowledge" generation the need to verify accelerates as well. This is why we need to be thoughtful and *slow down* when integrating these tools into our existing knowledge systems...if they are integrated at all. It is a choice after all. Just because a generative AI tool is offering you citations to back up its assertions does not mean the citations refer to actual documents, or if the documents exist, that the they back up the claims that are being made [@Liu:2023].

Is it realistic for us to be checking the work of these systems? Wouldn't it be better if it was the other way around?

I'm reminded of the nudges my Subaru Outback will give me if I begin to stray out of my lane. These nudges gently move the car back into the lane, and prompt me to make additional corrections. They get me to pay better attention. But the automated system doesn't take full control of the car. Subaru's [lane keeping] system is no doubt a machine learning model that has been trained on many hour of driving video. But the complete system is oriented around helping (not replacing) drivers, and reducing car accidents, rather than trying to create a fully automated self driving car. I'm always struck by how gentle, collaborative and helpful these nudges are, and I can't help but wonder what an equivalent would look like in information seeking behavior, where rather than generating complete answers to questions, or posing as an intelligent conversation partner, the system collaborates *with* us.

At work we've been looking to integrate OpenAI's [Whisper] into our institutional repository, so that we can generate transcripts for video and audio that lack them. There were some routine technical difficulties involving [integrating] on-premises software with on-demand services in the cloud, where we could have access to compute resources with GPUs. But from my perspective it seemed that the primary problems we ran into were policy questions around what types of review and correction needed to happen to the generated transcripts, and how to make these checks part of our workflow. This is all still a work in progress, but one small experiment I got to try was helping to visualize the *confidence level* that Whisper reports for words in its transcript:

<figure>
<img class="img-fluid" src="/images/whisper-transcript.png">
<figcaption>Viewing a Whisper generated transcript with confidence levels</figcaption>
</figure>

[whisper-transcript] is a tiny piece of software, a Web Component you can drop into any web page using Whisper's JSON output (a demo is running [here]). It's clearly not a complete system for correcting the transcript, but simply a way of listening to the media, while seeing the transcription, and the models confidence about its transcription. I'm mentioning it here because it felt like a clumsy attempt at providing these kinds of nudges to someone reviewing the transcript. 

A novel, a car and a transcript make for a kind of unruly trio. This post was just me expressing my hope that we see a move towards specialized computer assisted interfaces that don't create more work for us, and that the promises of automated systems that replace people get left behind in the dust (again).

PS. Powers' [book], like the others I've read, is beautifully written. The life stories of his characters really stick with you, and the descriptions of the ocean and the natural world will transport you in the best way possible.

---

[Playground]: https://www.richardpowers.net/playground/
[Richard Powers]: https://en.wikipedia.org/wiki/Richard_Powers
[Makatea]: https://en.wikipedia.org/wiki/Makatea
[Large Language Models]: https://en.wikipedia.org/wiki/Large_language_model
[lane keeping]: https://en.wikipedia.org/wiki/Lane_departure_warning_system#Lane_keeping_and_next_technologies 
[Whisper]: https://openai.com/index/whisper/
[whisper-transcript]: https://github.com/edsu/whisper-transcript/
[here]: https://edsu.github.io/whisper-transcript/
[integrating]: https://github.com/sul-dlss/speech-to-text#readme
[book]: https://www.richardpowers.net/playground/
